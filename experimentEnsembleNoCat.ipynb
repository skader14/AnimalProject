{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janetkim/myenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Animal Type</th>\n",
       "      <th>Sex upon Intake</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color Category</th>\n",
       "      <th>Age in Days</th>\n",
       "      <th>Intake Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1186</td>\n",
       "      <td>1</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>330.0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>3</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1488</td>\n",
       "      <td>0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intake Type  Intake Condition  Animal Type  Sex upon Intake  Breed  \\\n",
       "0            4                11            1                3   1186   \n",
       "1            4                11            1                1    281   \n",
       "2            3                11            0                2   1125   \n",
       "3            2                11            1                2   1488   \n",
       "4            3                11            1                2   1329   \n",
       "\n",
       "   Color Category  Age in Days  Intake Hour  Weekday  Season  \n",
       "0               1       2920.0           12        6       2  \n",
       "1               1        330.0           18        3       1  \n",
       "2               3        730.0            0        3       1  \n",
       "3               0        730.0           12        5       3  \n",
       "4               0       2190.0            9        1       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Helper: Simplify color into dark/light/mixed/other \n",
    "def simplify_color(color):\n",
    "    color = str(color).lower()\n",
    "    light = ['white', 'cream', 'tan', 'yellow', 'fawn']\n",
    "    dark = ['black', 'brown', 'chocolate', 'blue', 'gray', 'grey']\n",
    "    if any(w in color for w in light) and any(w in color for w in dark):\n",
    "        return 'mixed'\n",
    "    elif any(w in color for w in light):\n",
    "        return 'light'\n",
    "    elif any(w in color for w in dark):\n",
    "        return 'dark'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# Helper: Convert age to days \n",
    "def age_to_days(age_str):\n",
    "    if pd.isnull(age_str):\n",
    "        return np.nan\n",
    "    num, unit = age_str.split()\n",
    "    num = int(num)\n",
    "    unit = unit.lower()\n",
    "    if 'day' in unit:\n",
    "        return num\n",
    "    elif 'week' in unit:\n",
    "        return num * 7\n",
    "    elif 'month' in unit:\n",
    "        return num * 30\n",
    "    elif 'year' in unit:\n",
    "        return num * 365\n",
    "    return np.nan\n",
    "\n",
    "# Load and preprocess train.csv\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Get the target and id column\n",
    "target_col = \"Outcome Type\"\n",
    "id_col = \"Id\"\n",
    "\n",
    "# drop unneeded columns\n",
    "drop_cols = ['Outcome Time', 'Found Location', 'Date of Birth', 'Name', target_col, id_col]\n",
    "X = train_df.drop(columns=drop_cols, errors='ignore')\n",
    "y = train_df[target_col]\n",
    "\n",
    "# Label encode target\n",
    "le_y = LabelEncoder()\n",
    "y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "# Feature engineering\n",
    "X['Color Category'] = X['Color'].apply(simplify_color)\n",
    "X.drop(columns=['Color'], inplace=True)\n",
    "\n",
    "X['Age in Days'] = X['Age upon Intake'].apply(age_to_days)\n",
    "X.drop(columns=['Age upon Intake'], inplace=True)\n",
    "\n",
    "# DID NOT USE: this would result in \"0\" for animals less than 1wk old\n",
    "# X['Age Group'] = X['Age in Weeks'].apply(age_group)\n",
    "# X = X.drop(columns=['Age in Weeks'])\n",
    "\n",
    "# Categorize intake time into hour, weekday, and season (slightly improved accuracy by about .01%: .62 to .63)\n",
    "X['Intake Time'] = pd.to_datetime(train_df['Intake Time'], errors='coerce')\n",
    "X['Intake Hour'] = X['Intake Time'].dt.hour\n",
    "X['Weekday'] = X['Intake Time'].dt.weekday\n",
    "X['Season'] = X['Intake Time'].dt.month.map({\n",
    "    12: 'winter', 1: 'winter', 2: 'winter',\n",
    "    3: 'spring', 4: 'spring', 5: 'spring',\n",
    "    6: 'summer', 7: 'summer', 8: 'summer',\n",
    "    9: 'fall', 10: 'fall', 11: 'fall'\n",
    "})\n",
    "\n",
    "# Drop intake time after using to create new columns\n",
    "X.drop(columns=['Intake Time'], inplace=True, errors='ignore')\n",
    "\n",
    "# Fill missing values\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].fillna(\"Unknown\")\n",
    "    else:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Convert categoricals to category dtype for LightGBM\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "# Convert all categorical columns to numeric codes for XGBoost\n",
    "X_numeric = X.copy()\n",
    "for col in X_numeric.select_dtypes(include='category').columns:\n",
    "    X_numeric[col] = X_numeric[col].cat.codes\n",
    "\n",
    "X.head()\n",
    "X_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# objective function for the lgbm \n",
    "def lgbm_objective(trial):\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': len(le_y.classes_),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 63),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5.0),\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 200,\n",
    "        'verbosity': -1,\n",
    "        'is_unbalance': True\n",
    "    }\n",
    "\n",
    "    # do a kfold cross validation and return the balanced accuracy score\n",
    "    model = LGBMClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_preds = cross_val_predict(model, X, y_encoded, cv=skf, method=\"predict\")\n",
    "    return balanced_accuracy_score(y_encoded, y_preds)\n",
    "\n",
    "# objective function for xgb\n",
    "def xgb_objective(trial):\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(le_y.classes_),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5.0),\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 200,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'mlogloss'\n",
    "    }\n",
    "    \n",
    "    # do a kfold cross validation and return the balanced accuracy score\n",
    "    model = XGBClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_preds = cross_val_predict(model, X_numeric, y_encoded, cv=skf, method=\"predict\")\n",
    "    return balanced_accuracy_score(y_encoded, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 23:53:30,091] A new study created in memory with name: no-name-16d1ee6e-79ca-4bec-b9e3-f9364828569a\n",
      "[I 2025-04-15 23:53:37,214] Trial 0 finished with value: 0.3984862277002101 and parameters: {'learning_rate': 0.1487388665567224, 'max_depth': 3, 'num_leaves': 54, 'min_child_samples': 47, 'subsample': 0.6064490309479724, 'colsample_bytree': 0.6446360917691923, 'reg_alpha': 4.617543554758913, 'reg_lambda': 2.449597336919772}. Best is trial 0 with value: 0.3984862277002101.\n",
      "[I 2025-04-15 23:53:56,391] Trial 1 finished with value: 0.40543215024488166 and parameters: {'learning_rate': 0.0497386308741707, 'max_depth': 7, 'num_leaves': 57, 'min_child_samples': 45, 'subsample': 0.7967649129320018, 'colsample_bytree': 0.7242924997376072, 'reg_alpha': 2.6508938749420623, 'reg_lambda': 2.670885885317549}. Best is trial 1 with value: 0.40543215024488166.\n",
      "[I 2025-04-15 23:54:09,111] Trial 2 finished with value: 0.4058292541874081 and parameters: {'learning_rate': 0.10037797474064049, 'max_depth': 9, 'num_leaves': 17, 'min_child_samples': 69, 'subsample': 0.7622914481735117, 'colsample_bytree': 0.9310014336786728, 'reg_alpha': 3.0356613619738404, 'reg_lambda': 4.596422189029381}. Best is trial 2 with value: 0.4058292541874081.\n",
      "[I 2025-04-15 23:54:24,843] Trial 3 finished with value: 0.39633229224295796 and parameters: {'learning_rate': 0.02291330724624362, 'max_depth': 6, 'num_leaves': 27, 'min_child_samples': 56, 'subsample': 0.899011401667388, 'colsample_bytree': 0.9165454395903374, 'reg_alpha': 3.817688878778393, 'reg_lambda': 3.4066119762224645}. Best is trial 2 with value: 0.4058292541874081.\n",
      "[I 2025-04-15 23:54:39,199] Trial 4 finished with value: 0.40515328502913067 and parameters: {'learning_rate': 0.06695526149991685, 'max_depth': 12, 'num_leaves': 17, 'min_child_samples': 72, 'subsample': 0.5460497488400939, 'colsample_bytree': 0.7482020275654926, 'reg_alpha': 3.582583024134853, 'reg_lambda': 1.3512976181786867}. Best is trial 2 with value: 0.4058292541874081.\n",
      "[I 2025-04-15 23:54:48,887] Trial 5 finished with value: 0.4038348396381302 and parameters: {'learning_rate': 0.16071057142179612, 'max_depth': 4, 'num_leaves': 17, 'min_child_samples': 90, 'subsample': 0.7756525355023469, 'colsample_bytree': 0.6704248194995097, 'reg_alpha': 3.825930780450308, 'reg_lambda': 3.927844059634719}. Best is trial 2 with value: 0.4058292541874081.\n",
      "[I 2025-04-15 23:55:18,370] Trial 6 finished with value: 0.4056949653027916 and parameters: {'learning_rate': 0.03311460171733144, 'max_depth': 12, 'num_leaves': 51, 'min_child_samples': 63, 'subsample': 0.8609957075749757, 'colsample_bytree': 0.6875546241868208, 'reg_alpha': 1.1598641219695782, 'reg_lambda': 3.8343118542275163}. Best is trial 2 with value: 0.4058292541874081.\n",
      "[I 2025-04-15 23:55:26,777] Trial 7 finished with value: 0.39863065628168765 and parameters: {'learning_rate': 0.17364597760367242, 'max_depth': 3, 'num_leaves': 42, 'min_child_samples': 61, 'subsample': 0.6573731158585039, 'colsample_bytree': 0.574816829949244, 'reg_alpha': 4.870778807026471, 'reg_lambda': 4.975347106486511}. Best is trial 2 with value: 0.4058292541874081.\n",
      "[I 2025-04-15 23:55:51,846] Trial 8 finished with value: 0.41175408826842225 and parameters: {'learning_rate': 0.13464729641900725, 'max_depth': 12, 'num_leaves': 45, 'min_child_samples': 62, 'subsample': 0.9611342437961523, 'colsample_bytree': 0.7663034067045726, 'reg_alpha': 3.570429780529964, 'reg_lambda': 0.5941949693321108}. Best is trial 8 with value: 0.41175408826842225.\n",
      "[I 2025-04-15 23:56:19,885] Trial 9 finished with value: 0.40854699738206895 and parameters: {'learning_rate': 0.09316165062256211, 'max_depth': 9, 'num_leaves': 50, 'min_child_samples': 69, 'subsample': 0.8692637946396373, 'colsample_bytree': 0.5110017357517389, 'reg_alpha': 1.7801089549649536, 'reg_lambda': 3.9111222094366607}. Best is trial 8 with value: 0.41175408826842225.\n",
      "[I 2025-04-15 23:56:38,485] Trial 10 finished with value: 0.41453111001660153 and parameters: {'learning_rate': 0.19996142340711798, 'max_depth': 10, 'num_leaves': 36, 'min_child_samples': 19, 'subsample': 0.9714556045923706, 'colsample_bytree': 0.8536192138485449, 'reg_alpha': 0.5852214036518917, 'reg_lambda': 0.17413051234551336}. Best is trial 10 with value: 0.41453111001660153.\n",
      "[I 2025-04-15 23:56:55,420] Trial 11 finished with value: 0.4160405172301907 and parameters: {'learning_rate': 0.19868073778043369, 'max_depth': 10, 'num_leaves': 34, 'min_child_samples': 14, 'subsample': 0.9967037135503884, 'colsample_bytree': 0.8536672791661504, 'reg_alpha': 0.3555169542644959, 'reg_lambda': 0.1161555613220726}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:57:11,536] Trial 12 finished with value: 0.41378626949214264 and parameters: {'learning_rate': 0.19751039856217228, 'max_depth': 10, 'num_leaves': 32, 'min_child_samples': 11, 'subsample': 0.968540270498112, 'colsample_bytree': 0.8409176209546083, 'reg_alpha': 0.13990196304458613, 'reg_lambda': 0.040771777871883935}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:57:28,462] Trial 13 finished with value: 0.4151646225828144 and parameters: {'learning_rate': 0.19946780866567365, 'max_depth': 10, 'num_leaves': 34, 'min_child_samples': 10, 'subsample': 0.996188197416855, 'colsample_bytree': 0.99702149857659, 'reg_alpha': 0.1377939924013396, 'reg_lambda': 1.1974813578892403}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:57:44,930] Trial 14 finished with value: 0.4112725373374514 and parameters: {'learning_rate': 0.12030507410638294, 'max_depth': 10, 'num_leaves': 28, 'min_child_samples': 28, 'subsample': 0.9919574586172734, 'colsample_bytree': 0.9786542124499668, 'reg_alpha': 1.6447277254877921, 'reg_lambda': 1.2282690348477074}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:58:02,815] Trial 15 finished with value: 0.4131653252411217 and parameters: {'learning_rate': 0.17691584119844658, 'max_depth': 8, 'num_leaves': 36, 'min_child_samples': 30, 'subsample': 0.9045420995740003, 'colsample_bytree': 0.9794440777478057, 'reg_alpha': 0.24527304017320042, 'reg_lambda': 1.2607269331489352}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:58:17,503] Trial 16 finished with value: 0.4102693477551099 and parameters: {'learning_rate': 0.1792968380397134, 'max_depth': 11, 'num_leaves': 25, 'min_child_samples': 12, 'subsample': 0.6821553206396693, 'colsample_bytree': 0.8345314628200435, 'reg_alpha': 0.9369669541685063, 'reg_lambda': 1.9617604841599483}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:58:34,694] Trial 17 finished with value: 0.4093642639742329 and parameters: {'learning_rate': 0.1449522956757875, 'max_depth': 6, 'num_leaves': 44, 'min_child_samples': 29, 'subsample': 0.8213043053279331, 'colsample_bytree': 0.9052687338584573, 'reg_alpha': 1.8647081527132083, 'reg_lambda': 0.7428268921159271}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:58:52,586] Trial 18 finished with value: 0.4087908991853732 and parameters: {'learning_rate': 0.07257272044650517, 'max_depth': 8, 'num_leaves': 32, 'min_child_samples': 41, 'subsample': 0.9244980880870465, 'colsample_bytree': 0.8100585294454571, 'reg_alpha': 1.1077019939133415, 'reg_lambda': 1.8787151134322855}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:59:06,203] Trial 19 finished with value: 0.4107500323619823 and parameters: {'learning_rate': 0.12317024183028763, 'max_depth': 11, 'num_leaves': 23, 'min_child_samples': 19, 'subsample': 0.7021359695837813, 'colsample_bytree': 0.9829827515943288, 'reg_alpha': 0.05611789657447064, 'reg_lambda': 0.6718188540095937}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:59:25,900] Trial 20 finished with value: 0.41322012313638856 and parameters: {'learning_rate': 0.18943975791497258, 'max_depth': 9, 'num_leaves': 40, 'min_child_samples': 35, 'subsample': 0.50089102831851, 'colsample_bytree': 0.8920897565013779, 'reg_alpha': 0.6427370035046533, 'reg_lambda': 1.7624279453993812}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-15 23:59:43,874] Trial 21 finished with value: 0.41598918693699183 and parameters: {'learning_rate': 0.19763481809306996, 'max_depth': 10, 'num_leaves': 36, 'min_child_samples': 20, 'subsample': 0.9999752079359582, 'colsample_bytree': 0.8625295128361536, 'reg_alpha': 0.5849443724500576, 'reg_lambda': 0.005242641804629758}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-16 00:00:01,060] Trial 22 finished with value: 0.4149272566050236 and parameters: {'learning_rate': 0.162165030916984, 'max_depth': 11, 'num_leaves': 32, 'min_child_samples': 20, 'subsample': 0.9947665583133092, 'colsample_bytree': 0.7748688929215442, 'reg_alpha': 0.6582047372328269, 'reg_lambda': 0.034407373568284404}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-16 00:00:20,397] Trial 23 finished with value: 0.41380337110304105 and parameters: {'learning_rate': 0.18665004471048965, 'max_depth': 10, 'num_leaves': 37, 'min_child_samples': 20, 'subsample': 0.9351078900488901, 'colsample_bytree': 0.8786633861175555, 'reg_alpha': 1.3793898355269036, 'reg_lambda': 0.4561246604129163}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-16 00:00:40,963] Trial 24 finished with value: 0.41078637923586997 and parameters: {'learning_rate': 0.1756475942439955, 'max_depth': 7, 'num_leaves': 46, 'min_child_samples': 12, 'subsample': 0.8576569704496918, 'colsample_bytree': 0.8039555373072999, 'reg_alpha': 2.20569281863805, 'reg_lambda': 0.9633493641339037}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-16 00:00:53,909] Trial 25 finished with value: 0.4116933797135661 and parameters: {'learning_rate': 0.15955198919315383, 'max_depth': 9, 'num_leaves': 22, 'min_child_samples': 10, 'subsample': 0.9992040155413278, 'colsample_bytree': 0.9268662167924077, 'reg_alpha': 0.42048233303879556, 'reg_lambda': 0.3748728847714984}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-16 00:01:10,869] Trial 26 finished with value: 0.41204488429812114 and parameters: {'learning_rate': 0.19894093792033102, 'max_depth': 11, 'num_leaves': 31, 'min_child_samples': 97, 'subsample': 0.939706636313805, 'colsample_bytree': 0.945175884465393, 'reg_alpha': 0.8445807346329142, 'reg_lambda': 1.0093082155206736}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-16 00:01:29,012] Trial 27 finished with value: 0.4129296176555742 and parameters: {'learning_rate': 0.16804640877921803, 'max_depth': 10, 'num_leaves': 37, 'min_child_samples': 24, 'subsample': 0.8932362848965838, 'colsample_bytree': 0.8758993580198718, 'reg_alpha': 0.01966542351137418, 'reg_lambda': 1.5837266069618843}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-16 00:01:54,075] Trial 28 finished with value: 0.41225119635962315 and parameters: {'learning_rate': 0.1440499360828102, 'max_depth': 8, 'num_leaves': 61, 'min_child_samples': 36, 'subsample': 0.8234176652035379, 'colsample_bytree': 0.7965601759739592, 'reg_alpha': 1.4294271031456254, 'reg_lambda': 2.459727216860982}. Best is trial 11 with value: 0.4160405172301907.\n",
      "[I 2025-04-16 00:02:14,678] Trial 29 finished with value: 0.4110412496736934 and parameters: {'learning_rate': 0.18697461094164375, 'max_depth': 11, 'num_leaves': 40, 'min_child_samples': 37, 'subsample': 0.72391918562575, 'colsample_bytree': 0.9500485683436103, 'reg_alpha': 2.271132930891843, 'reg_lambda': 2.909636867739834}. Best is trial 11 with value: 0.4160405172301907.\n"
     ]
    }
   ],
   "source": [
    "# use optuna to adjust hyperparameters for lgbm\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(lgbm_objective, n_trials=30)\n",
    "\n",
    "# get the model with highest accuracy\n",
    "best_lgbm_params = study_lgbm.best_params\n",
    "best_lgbm_params.update({\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(le_y.classes_),\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 200,\n",
    "    'verbosity': -1,\n",
    "    'is_unbalance': True\n",
    "})\n",
    "\n",
    "model_lgbm = LGBMClassifier(**best_lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 00:02:14,700] A new study created in memory with name: no-name-332d724f-662e-4a67-8000-3b750d92d591\n",
      "[I 2025-04-16 00:02:29,718] Trial 0 finished with value: 0.4094631820171082 and parameters: {'learning_rate': 0.09232834482440931, 'max_depth': 12, 'subsample': 0.9813988285780086, 'colsample_bytree': 0.5896194484195714, 'reg_alpha': 2.2260006045983993, 'reg_lambda': 4.227364319048787}. Best is trial 0 with value: 0.4094631820171082.\n",
      "[I 2025-04-16 00:02:37,085] Trial 1 finished with value: 0.4021488606296394 and parameters: {'learning_rate': 0.1956870368408444, 'max_depth': 5, 'subsample': 0.7840069465387474, 'colsample_bytree': 0.8149256362061087, 'reg_alpha': 3.4185989706672153, 'reg_lambda': 4.200436640566577}. Best is trial 0 with value: 0.4094631820171082.\n",
      "[I 2025-04-16 00:02:44,243] Trial 2 finished with value: 0.3786705545284648 and parameters: {'learning_rate': 0.02861073136024856, 'max_depth': 5, 'subsample': 0.7942550771833077, 'colsample_bytree': 0.6706475825456819, 'reg_alpha': 3.8467947406061214, 'reg_lambda': 1.7969929011179748}. Best is trial 0 with value: 0.4094631820171082.\n",
      "[I 2025-04-16 00:02:58,715] Trial 3 finished with value: 0.40948261655541013 and parameters: {'learning_rate': 0.051943359784192566, 'max_depth': 11, 'subsample': 0.9688355048110958, 'colsample_bytree': 0.8950611203887309, 'reg_alpha': 2.10860991023271, 'reg_lambda': 2.1588422322431144}. Best is trial 3 with value: 0.40948261655541013.\n",
      "[I 2025-04-16 00:03:12,836] Trial 4 finished with value: 0.40648079317953395 and parameters: {'learning_rate': 0.1468528009150436, 'max_depth': 11, 'subsample': 0.5352518203559025, 'colsample_bytree': 0.7775097795964263, 'reg_alpha': 4.307182651761588, 'reg_lambda': 2.9810010859579923}. Best is trial 3 with value: 0.40948261655541013.\n",
      "[I 2025-04-16 00:03:31,721] Trial 5 finished with value: 0.4079436285207098 and parameters: {'learning_rate': 0.14319202180347948, 'max_depth': 11, 'subsample': 0.5041708553053557, 'colsample_bytree': 0.9512016929737321, 'reg_alpha': 3.770132764982712, 'reg_lambda': 4.584563944882178}. Best is trial 3 with value: 0.40948261655541013.\n",
      "[I 2025-04-16 00:03:43,325] Trial 6 finished with value: 0.4145403601165351 and parameters: {'learning_rate': 0.150010047303993, 'max_depth': 8, 'subsample': 0.6044474485523257, 'colsample_bytree': 0.8477656154061611, 'reg_alpha': 0.12679981865051038, 'reg_lambda': 3.759926593473166}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:03:50,831] Trial 7 finished with value: 0.4021320024273705 and parameters: {'learning_rate': 0.19069751420876688, 'max_depth': 5, 'subsample': 0.7782461838934287, 'colsample_bytree': 0.8244851195020138, 'reg_alpha': 3.5767999177720644, 'reg_lambda': 3.5668351647359136}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:03:59,587] Trial 8 finished with value: 0.4026522211686522 and parameters: {'learning_rate': 0.12434849657078997, 'max_depth': 6, 'subsample': 0.7956220554071568, 'colsample_bytree': 0.5061538168273293, 'reg_alpha': 3.1466865011949525, 'reg_lambda': 0.8495142625766694}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:04:14,815] Trial 9 finished with value: 0.41244676808470143 and parameters: {'learning_rate': 0.19540725768134226, 'max_depth': 10, 'subsample': 0.5607472763400425, 'colsample_bytree': 0.8810444801541308, 'reg_alpha': 0.6580560639458188, 'reg_lambda': 0.05403418519103309}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:04:26,090] Trial 10 finished with value: 0.41124443457000226 and parameters: {'learning_rate': 0.09190015819676067, 'max_depth': 8, 'subsample': 0.6627118544526029, 'colsample_bytree': 0.9987669008265648, 'reg_alpha': 0.0005348950819986653, 'reg_lambda': 4.994260032802265}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:04:37,717] Trial 11 finished with value: 0.4143551371615718 and parameters: {'learning_rate': 0.16705108865435175, 'max_depth': 8, 'subsample': 0.620544798846225, 'colsample_bytree': 0.861670888352103, 'reg_alpha': 0.1754263359411028, 'reg_lambda': 0.24676728140872006}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:04:49,341] Trial 12 finished with value: 0.41248177320511126 and parameters: {'learning_rate': 0.16130363828715147, 'max_depth': 8, 'subsample': 0.6466611779545777, 'colsample_bytree': 0.6998036613043155, 'reg_alpha': 1.0841468109152168, 'reg_lambda': 1.3783870713933066}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:04:55,071] Trial 13 finished with value: 0.3920988894993691 and parameters: {'learning_rate': 0.16629211206351724, 'max_depth': 3, 'subsample': 0.6476448088322925, 'colsample_bytree': 0.8754553894199661, 'reg_alpha': 1.212253576635679, 'reg_lambda': 2.991620907537673}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:05:07,743] Trial 14 finished with value: 0.41365348238384475 and parameters: {'learning_rate': 0.11720275017303909, 'max_depth': 9, 'subsample': 0.602290327369436, 'colsample_bytree': 0.7278497683567108, 'reg_alpha': 0.28898162503412383, 'reg_lambda': 0.4081619120364831}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:05:17,389] Trial 15 finished with value: 0.41013425664256487 and parameters: {'learning_rate': 0.17075847453361637, 'max_depth': 7, 'subsample': 0.7186134800955863, 'colsample_bytree': 0.9507062331089737, 'reg_alpha': 1.5527068618208653, 'reg_lambda': 3.3451690572282}. Best is trial 6 with value: 0.4145403601165351.\n",
      "[I 2025-04-16 00:05:29,236] Trial 16 finished with value: 0.4149258216402334 and parameters: {'learning_rate': 0.13045037584228514, 'max_depth': 9, 'subsample': 0.8995959814961314, 'colsample_bytree': 0.8271672018240068, 'reg_alpha': 0.6596701040770394, 'reg_lambda': 2.510147653490786}. Best is trial 16 with value: 0.4149258216402334.\n",
      "[I 2025-04-16 00:05:40,848] Trial 17 finished with value: 0.40730684744947593 and parameters: {'learning_rate': 0.06270834683384047, 'max_depth': 9, 'subsample': 0.8901320718698856, 'colsample_bytree': 0.7665466173702393, 'reg_alpha': 1.7608884379118006, 'reg_lambda': 2.4915785505710564}. Best is trial 16 with value: 0.4149258216402334.\n",
      "[I 2025-04-16 00:05:49,870] Trial 18 finished with value: 0.4049311441377639 and parameters: {'learning_rate': 0.1377011016108154, 'max_depth': 7, 'subsample': 0.8726129762431009, 'colsample_bytree': 0.6540485910380474, 'reg_alpha': 4.990441303015961, 'reg_lambda': 3.7919734429924725}. Best is trial 16 with value: 0.4149258216402334.\n",
      "[I 2025-04-16 00:06:01,618] Trial 19 finished with value: 0.41396602453661197 and parameters: {'learning_rate': 0.10454029278540453, 'max_depth': 9, 'subsample': 0.8682275415331355, 'colsample_bytree': 0.8052690504409014, 'reg_alpha': 0.9190412059333014, 'reg_lambda': 2.8066125267982023}. Best is trial 16 with value: 0.4149258216402334.\n",
      "[I 2025-04-16 00:06:15,509] Trial 20 finished with value: 0.4158517740391792 and parameters: {'learning_rate': 0.07321430989697318, 'max_depth': 10, 'subsample': 0.7233536233601996, 'colsample_bytree': 0.9227742295116759, 'reg_alpha': 0.6139487781998956, 'reg_lambda': 1.5311501337947384}. Best is trial 20 with value: 0.4158517740391792.\n",
      "[I 2025-04-16 00:06:29,463] Trial 21 finished with value: 0.414611861512005 and parameters: {'learning_rate': 0.07458150306354924, 'max_depth': 10, 'subsample': 0.7144937188347268, 'colsample_bytree': 0.9378361759081549, 'reg_alpha': 0.5155013961045912, 'reg_lambda': 1.6644625090684404}. Best is trial 20 with value: 0.4158517740391792.\n",
      "[I 2025-04-16 00:06:43,525] Trial 22 finished with value: 0.4152336703683336 and parameters: {'learning_rate': 0.07532649543897744, 'max_depth': 10, 'subsample': 0.721292201764816, 'colsample_bytree': 0.9362994784825059, 'reg_alpha': 0.611580386561183, 'reg_lambda': 1.4454284912280402}. Best is trial 20 with value: 0.4158517740391792.\n",
      "[I 2025-04-16 00:06:56,324] Trial 23 finished with value: 0.4052562298822789 and parameters: {'learning_rate': 0.037793855298848086, 'max_depth': 10, 'subsample': 0.725133737893573, 'colsample_bytree': 0.9979741526793541, 'reg_alpha': 2.734490399581374, 'reg_lambda': 1.085671659124784}. Best is trial 20 with value: 0.4158517740391792.\n",
      "[I 2025-04-16 00:07:12,678] Trial 24 finished with value: 0.4030193772733206 and parameters: {'learning_rate': 0.015601760652957791, 'max_depth': 12, 'subsample': 0.8379350265742322, 'colsample_bytree': 0.9131684272527977, 'reg_alpha': 1.4529153163120754, 'reg_lambda': 2.1782375180311213}. Best is trial 20 with value: 0.4158517740391792.\n",
      "[I 2025-04-16 00:07:26,223] Trial 25 finished with value: 0.4159394044433206 and parameters: {'learning_rate': 0.07542686785819591, 'max_depth': 10, 'subsample': 0.9394799590401374, 'colsample_bytree': 0.9278556297737844, 'reg_alpha': 0.7920882742830682, 'reg_lambda': 0.7729102701744033}. Best is trial 25 with value: 0.4159394044433206.\n",
      "[I 2025-04-16 00:07:39,746] Trial 26 finished with value: 0.41577230132264037 and parameters: {'learning_rate': 0.07499632618675278, 'max_depth': 10, 'subsample': 0.9351176456786138, 'colsample_bytree': 0.969172778257144, 'reg_alpha': 0.8901486617087166, 'reg_lambda': 0.7328865064431176}. Best is trial 25 with value: 0.4159394044433206.\n",
      "[I 2025-04-16 00:07:56,515] Trial 27 finished with value: 0.41267248759804 and parameters: {'learning_rate': 0.054264000151855354, 'max_depth': 12, 'subsample': 0.9351023745125724, 'colsample_bytree': 0.9699069145167317, 'reg_alpha': 1.8454505104697267, 'reg_lambda': 0.6940294950188237}. Best is trial 25 with value: 0.4159394044433206.\n",
      "[I 2025-04-16 00:08:11,941] Trial 28 finished with value: 0.4168985459534332 and parameters: {'learning_rate': 0.07973680073897411, 'max_depth': 11, 'subsample': 0.9364202544010715, 'colsample_bytree': 0.9182896557427036, 'reg_alpha': 1.0276455029720941, 'reg_lambda': 1.0162294893155421}. Best is trial 28 with value: 0.4168985459534332.\n",
      "[I 2025-04-16 00:08:28,673] Trial 29 finished with value: 0.41517077544307346 and parameters: {'learning_rate': 0.09667023658203258, 'max_depth': 12, 'subsample': 0.9629724614271861, 'colsample_bytree': 0.9152931518795607, 'reg_alpha': 2.4250758347361616, 'reg_lambda': 1.1595630618452297}. Best is trial 28 with value: 0.4168985459534332.\n"
     ]
    }
   ],
   "source": [
    "# adjust hyperparameters for xgb model\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(xgb_objective, n_trials=30)\n",
    "\n",
    "# get the model with highest accuracy\n",
    "best_xgb_params = study_xgb.best_params\n",
    "best_xgb_params.update({\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': len(le_y.classes_),\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 200,\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'mlogloss'\n",
    "})\n",
    "\n",
    "model_xgb = XGBClassifier(**best_xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.4237261841269383\n",
      "Balanced Accuracy (Weighted Ensemble): 0.4247346533991651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data to training and test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "X_train_numeric, X_val_numeric = X_numeric.loc[X_train.index], X_numeric.loc[X_val.index]\n",
    "\n",
    "# train both models using the training set\n",
    "model_lgbm.fit(X_train, y_train)\n",
    "model_xgb.fit(X_train_numeric, y_train)\n",
    "\n",
    "# Ensemble with soft voting\n",
    "probs_lgbm = model_lgbm.predict_proba(X_val)\n",
    "probs_xgb  = model_xgb.predict_proba(X_val_numeric)\n",
    "\n",
    "# Equal-weight ensemble\n",
    "avg_probs = (probs_lgbm + probs_xgb) / 2\n",
    "y_pred_ensemble = np.argmax(avg_probs, axis=1)\n",
    "val_score_ensemble = balanced_accuracy_score(y_val, y_pred_ensemble)\n",
    "\n",
    "print(\"Balanced Accuracy:\", val_score_ensemble)\n",
    "\n",
    "# Weighted ensemble to improve accuracy\n",
    "avg_probs = (0.7 * probs_xgb + 0.3 * probs_lgbm)\n",
    "y_pred_weighted = np.argmax(avg_probs, axis=1)\n",
    "val_score_weighted = balanced_accuracy_score(y_val, y_pred_weighted)\n",
    "\n",
    "print(\"Balanced Accuracy (Weighted Ensemble):\", val_score_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Animal Type</th>\n",
       "      <th>Sex upon Intake</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color Category</th>\n",
       "      <th>Age in Days</th>\n",
       "      <th>Intake Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Beagle Mix</td>\n",
       "      <td>other</td>\n",
       "      <td>730</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Sick</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>other</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Doberman Pinsch/Australian Cattle Dog</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1460</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>Pit Bull</td>\n",
       "      <td>mixed</td>\n",
       "      <td>150</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stray</td>\n",
       "      <td>Injured</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>mixed</td>\n",
       "      <td>730</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Intake Type Intake Condition Animal Type Sex upon Intake  \\\n",
       "0       Stray           Normal         Dog   Neutered Male   \n",
       "1       Stray             Sick         Cat   Intact Female   \n",
       "2       Stray           Normal         Dog   Neutered Male   \n",
       "3       Stray           Normal         Dog   Intact Female   \n",
       "4       Stray          Injured         Cat   Intact Female   \n",
       "\n",
       "                                   Breed Color Category  Age in Days  \\\n",
       "0                             Beagle Mix          other          730   \n",
       "1                 Domestic Shorthair Mix          other           28   \n",
       "2  Doberman Pinsch/Australian Cattle Dog          mixed         1460   \n",
       "3                               Pit Bull          mixed          150   \n",
       "4                 Domestic Shorthair Mix          mixed          730   \n",
       "\n",
       "   Intake Hour  Weekday  Season  \n",
       "0           16        3  winter  \n",
       "1            7        0    fall  \n",
       "2           10        6  summer  \n",
       "3           18        5  summer  \n",
       "4           10        5  winter  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the model to the test data\n",
    "# === Load and preprocess test.csv ===\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_ids = test_df['Id']\n",
    "\n",
    "# Drop columns not used in prediction\n",
    "drop_cols_test = ['Found Location', 'Date of Birth', 'Id']\n",
    "X_test = test_df.drop(columns=drop_cols_test, errors='ignore')\n",
    "\n",
    "# Feature engineering (same as training)\n",
    "X_test['Color Category'] = X_test['Color'].apply(simplify_color)\n",
    "X_test.drop(columns=['Color'], inplace=True)\n",
    "\n",
    "X_test['Age in Days'] = X_test['Age upon Intake'].apply(age_to_days)\n",
    "X_test.drop(columns=['Age upon Intake'], inplace=True)\n",
    "\n",
    "X_test['Intake Time'] = pd.to_datetime(test_df['Intake Time'], errors='coerce')\n",
    "X_test['Intake Hour'] = X_test['Intake Time'].dt.hour\n",
    "X_test['Weekday'] = X_test['Intake Time'].dt.weekday\n",
    "X_test['Season'] = X_test['Intake Time'].dt.month.map({\n",
    "    12: 'winter', 1: 'winter', 2: 'winter',\n",
    "    3: 'spring', 4: 'spring', 5: 'spring',\n",
    "    6: 'summer', 7: 'summer', 8: 'summer',\n",
    "    9: 'fall', 10: 'fall', 11: 'fall'\n",
    "})\n",
    "X_test.drop(columns=['Intake Time'], inplace=True, errors='ignore')\n",
    "\n",
    "# Fill missing values\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].dtype == 'object':\n",
    "        X_test[col] = X_test[col].fillna(\"Unknown\")\n",
    "    else:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].median())\n",
    "\n",
    "# Ensure categorical types match training\n",
    "for col in categorical_cols:\n",
    "    if col in X_test.columns:\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "# Convert all categorical columns to numeric codes for XGBoost\n",
    "X_test_numeric = X_test.copy()\n",
    "for col in X_test_numeric.select_dtypes(include='category').columns:\n",
    "    X_test_numeric[col] = X_test_numeric[col].cat.codes\n",
    "\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test\n",
    "probs_lgbm_test = model_lgbm.predict_proba(X_test)\n",
    "probs_xgb_test  = model_xgb.predict_proba(X_test_numeric)\n",
    "\n",
    "# for weighted ensemble\n",
    "avg_probs_test = (\n",
    "    0.7 * probs_xgb_test +\n",
    "    0.3 * probs_lgbm_test\n",
    ")\n",
    "\n",
    "# equal weight ensemble\n",
    "# avg_probs_test = (probs_lgbm_test + probs_xgb_test) / 2\n",
    "\n",
    "# predict the labels\n",
    "y_test_pred = np.argmax(avg_probs_test, axis=1)\n",
    "y_test_labels = le_y.inverse_transform(y_test_pred)\n",
    "\n",
    "# create the csv file\n",
    "submission = pd.DataFrame({'Id': test_ids, 'Outcome Type': y_test_labels})\n",
    "submission.to_csv(\"submission_ensemble.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
