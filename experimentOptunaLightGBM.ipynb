{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89f2974",
   "metadata": {},
   "source": [
    "This file was another attempt with slightly different preprocessing and tuning techniques for LightGBM. It did not yield us results higher than our final model, so we didn't end up using it. This model used the breed and color bucketing. It was one of our later trials, and definitely a more efficient approach to hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5183c59d",
   "metadata": {},
   "source": [
    "Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d2d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier  # For KNN\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Helper Functions ===\n",
    "def simplify_color(color_str):\n",
    "    \"\"\"\n",
    "    Map raw color strings to a smaller set of standardized categories.\n",
    "    This function checks for the presence of common color keywords.\n",
    "    \"\"\"\n",
    "    if pd.isna(color_str):\n",
    "        return \"unknown\"\n",
    "    color_str = color_str.lower()\n",
    "    if \"black\" in color_str:\n",
    "        return \"black\"\n",
    "    elif \"brown\" in color_str:\n",
    "        return \"brown\"\n",
    "    elif \"white\" in color_str:\n",
    "        return \"white\"\n",
    "    elif \"tan\" in color_str or \"gold\" in color_str:\n",
    "        return \"tan_gold\"\n",
    "    elif \"grey\" in color_str or \"gray\" in color_str:\n",
    "        return \"gray\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "def age_to_weeks(age_str):\n",
    "    \"\"\"\n",
    "    Convert an age string into estimated weeks.\n",
    "    e.g., \"2 years\" becomes 104 weeks and \"6 months\" becomes about 24 weeks.\n",
    "    \"\"\"\n",
    "    if pd.isna(age_str):\n",
    "        return np.nan\n",
    "    tokens = age_str.split()\n",
    "    if len(tokens) < 2:\n",
    "        return np.nan\n",
    "    if 'year' in tokens[1]:\n",
    "        return float(tokens[0]) * 52\n",
    "    elif 'month' in tokens[1]:\n",
    "        return float(tokens[0]) * 4\n",
    "    elif 'week' in tokens[1]:\n",
    "        return float(tokens[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "breed_size = {\n",
    "    # SMALL (<20 lbs avg)\n",
    "    'chihuahua':        'small',\n",
    "    'pembroke welsh corgi':'small',\n",
    "    'pug':               'small',\n",
    "    'yorkshire terrier':'small',\n",
    "    'dachshund':         'small',\n",
    "    'pomeranian':        'small',\n",
    "    'papillon':          'small',\n",
    "    'shih tzu':          'small',\n",
    "    'maltese':           'small',\n",
    "    'rat terrier':       'small',\n",
    "    'jack russell terrier':'small',\n",
    "    'west highland white terrier':'small',\n",
    "    # MEDIUM (20–50 lbs avg)\n",
    "    'border collie':     'medium',\n",
    "    'australian cattle dog':'medium',\n",
    "    'beagle':            'medium',\n",
    "    'boston terrier':    'medium',\n",
    "    'cocker spaniel':    'medium',\n",
    "    'cairn terrier':     'medium',\n",
    "    'bichon frise':      'medium',\n",
    "    'boston terrier':    'medium',\n",
    "    'siberian husky':    'medium',\n",
    "    # LARGE (50+ lbs avg)\n",
    "    'labrador retriever':'large',\n",
    "    'golden retriever':  'large',\n",
    "    'german shepherd':   'large',\n",
    "    'rottweiler':        'large',\n",
    "    ' dob':              'large',  # for “doberman”\n",
    "    'boxer':             'large',\n",
    "    'great dane':        'large',\n",
    "    'mastiff':           'large',\n",
    "    'newfoundland':      'large',\n",
    "    'bernese mountain dog':'large',\n",
    "    'great pyrenees':    'large',\n",
    "    'alaskan malamute':  'large',\n",
    "    'cane corso':        'large',\n",
    "    'doberman pinscher': 'large',\n",
    "    'chow chow':         'large',\n",
    "    # …add more breeds as needed…\n",
    "}\n",
    "\n",
    "# 2) Fallback keyword sets for truly rare / unlisted mixes\n",
    "small_keys = ['chihuahua','toy','pomeranian','papillon','yorkshire','pug']\n",
    "large_keys = ['mastiff','wolfhound','dane','newfoundland','retriever','shepherd','rottweiler','boxer','bulldog','malamute']\n",
    "\n",
    "def size_from_breed(breed):\n",
    "    b = breed.lower().replace('mix','').strip()\n",
    "    # split on slashes\n",
    "    components = [c.strip() for c in b.replace('/',',').split(',')]\n",
    "    sizes = []\n",
    "    for comp in components:\n",
    "        # exact lookup?\n",
    "        if comp in breed_size:\n",
    "            sizes.append(breed_size[comp])\n",
    "        else:\n",
    "            # fallback to keyword scan\n",
    "            if any(k in comp for k in small_keys):\n",
    "                sizes.append('small')\n",
    "            elif any(k in comp for k in large_keys):\n",
    "                sizes.append('large')\n",
    "            else:\n",
    "                sizes.append('medium')\n",
    "    # mixture takes the LARGEST of its parents\n",
    "    if 'large'  in sizes: return 'large'\n",
    "    if 'medium' in sizes: return 'medium'\n",
    "    return 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9023a55",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeaffb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical cols Index(['Intake Type', 'Intake Condition', 'Animal Type', 'Sex upon Intake',\n",
      "       'Color Category'],\n",
      "      dtype='object')\n",
      "Processed feature sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age in Weeks</th>\n",
       "      <th>breed_prob_Adoption</th>\n",
       "      <th>breed_prob_Died</th>\n",
       "      <th>breed_prob_Euthanasia</th>\n",
       "      <th>breed_prob_Return to Owner</th>\n",
       "      <th>breed_prob_Transfer</th>\n",
       "      <th>Intake Type_Euthanasia Request</th>\n",
       "      <th>Intake Type_Owner Surrender</th>\n",
       "      <th>Intake Type_Public Assist</th>\n",
       "      <th>Intake Type_Stray</th>\n",
       "      <th>...</th>\n",
       "      <th>Animal Type_Dog</th>\n",
       "      <th>Sex upon Intake_Intact Male</th>\n",
       "      <th>Sex upon Intake_Neutered Male</th>\n",
       "      <th>Sex upon Intake_Spayed Female</th>\n",
       "      <th>Sex upon Intake_Unknown</th>\n",
       "      <th>Color Category_brown</th>\n",
       "      <th>Color Category_gray</th>\n",
       "      <th>Color Category_other</th>\n",
       "      <th>Color Category_tan_gold</th>\n",
       "      <th>Color Category_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.564190</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>0.028917</td>\n",
       "      <td>0.033653</td>\n",
       "      <td>0.356662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.552352</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.022285</td>\n",
       "      <td>0.193314</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312.0</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age in Weeks  breed_prob_Adoption  breed_prob_Died  breed_prob_Euthanasia  \\\n",
       "0         416.0             0.000000         0.000000               0.000000   \n",
       "1          44.0             0.654545         0.000000               0.000000   \n",
       "2         104.0             0.564190         0.016577               0.028917   \n",
       "3         104.0             0.552352         0.004775               0.022285   \n",
       "4         312.0             0.340000         0.000000               0.000000   \n",
       "\n",
       "   breed_prob_Return to Owner  breed_prob_Transfer  \\\n",
       "0                    0.600000             0.400000   \n",
       "1                    0.200000             0.145455   \n",
       "2                    0.033653             0.356662   \n",
       "3                    0.193314             0.227273   \n",
       "4                    0.400000             0.260000   \n",
       "\n",
       "   Intake Type_Euthanasia Request  Intake Type_Owner Surrender  \\\n",
       "0                             0.0                          0.0   \n",
       "1                             0.0                          0.0   \n",
       "2                             0.0                          0.0   \n",
       "3                             0.0                          1.0   \n",
       "4                             0.0                          0.0   \n",
       "\n",
       "   Intake Type_Public Assist  Intake Type_Stray  ...  Animal Type_Dog  \\\n",
       "0                        0.0                1.0  ...              1.0   \n",
       "1                        0.0                1.0  ...              1.0   \n",
       "2                        1.0                0.0  ...              0.0   \n",
       "3                        0.0                0.0  ...              1.0   \n",
       "4                        1.0                0.0  ...              1.0   \n",
       "\n",
       "   Sex upon Intake_Intact Male  Sex upon Intake_Neutered Male  \\\n",
       "0                          0.0                            0.0   \n",
       "1                          1.0                            0.0   \n",
       "2                          0.0                            1.0   \n",
       "3                          0.0                            1.0   \n",
       "4                          0.0                            1.0   \n",
       "\n",
       "   Sex upon Intake_Spayed Female  Sex upon Intake_Unknown  \\\n",
       "0                            1.0                      0.0   \n",
       "1                            0.0                      0.0   \n",
       "2                            0.0                      0.0   \n",
       "3                            0.0                      0.0   \n",
       "4                            0.0                      0.0   \n",
       "\n",
       "   Color Category_brown  Color Category_gray  Color Category_other  \\\n",
       "0                   0.0                  0.0                   0.0   \n",
       "1                   0.0                  0.0                   0.0   \n",
       "2                   0.0                  0.0                   1.0   \n",
       "3                   0.0                  0.0                   1.0   \n",
       "4                   0.0                  0.0                   0.0   \n",
       "\n",
       "   Color Category_tan_gold  Color Category_white  \n",
       "0                      0.0                   1.0  \n",
       "1                      0.0                   1.0  \n",
       "2                      0.0                   0.0  \n",
       "3                      0.0                   0.0  \n",
       "4                      0.0                   0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === 1. Load and Subsample Data ===\n",
    "# For prototyping, we select a stratified random sample of ~40,000 rows\n",
    "# to maintain the same target distribution as the full dataset.\n",
    "df_full = pd.read_csv(\"train.csv\")\n",
    "# Option A: Using groupby with sample (ensures stratification)\n",
    "# sample_fraction = 40000 / len(df_full)\n",
    "# sample_df = df_full.groupby(\"Outcome Type\", group_keys=False).apply(lambda x: x.sample(frac=sample_fraction, random_state=42))\n",
    "# Option B (alternative): Using train_test_split's stratify option:\n",
    "sample_df, _ = train_test_split(df_full, train_size=50000, stratify=df_full[\"Outcome Type\"], random_state=42)\n",
    "\n",
    "# === 2. Target & ID Setup ===\n",
    "target_col = \"Outcome Type\"\n",
    "id_col = \"Id\"\n",
    "# Drop columns that are either high-leakage or not available in the test set.\n",
    "# Here, we drop Outcome Time as well since it isn't present in the test data.\n",
    "drop_cols = ['Found Location', 'Date of Birth', 'Name', target_col, id_col, 'Outcome Time']\n",
    "X = df_full.drop(columns=drop_cols, errors='ignore')\n",
    "y = df_full[target_col]\n",
    "\n",
    "# === 3. Encode the Target Variable ===\n",
    "# Although there are only five outcomes, encoding ensures compatibility with all models.\n",
    "le_y = LabelEncoder()\n",
    "y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "# === 4. Feature Engineering ===\n",
    "# Simplify the 'Color' feature into standardized categories\n",
    "X['Color Category'] = X['Color'].apply(simplify_color)\n",
    "X = X.drop(columns=['Color'])\n",
    "\n",
    "# Convert Age to Weeks\n",
    "X['Age in Weeks'] = X['Age upon Intake'].apply(age_to_weeks)\n",
    "X.drop(columns=['Age upon Intake'], inplace=True)\n",
    "\n",
    "# Process Intake Time if necessary. Since Outcome Time is not used and not in test data,\n",
    "# we drop Intake Time as well (or extract features if desired).\n",
    "datetime_format = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "X['Intake Time'] = pd.to_datetime(X['Intake Time'], format=datetime_format, errors='coerce')\n",
    "# If you wish to derive time-based features (like hour or day of week), do it here.\n",
    "# For now, we drop it to ensure consistency with the test set.\n",
    "X = X.drop(columns=['Intake Time'])\n",
    "\n",
    "\n",
    "\n",
    "# --- target‑encode breed ###\n",
    "breed_counts = df_full.groupby(['Breed','Outcome Type']).size()\\\n",
    "                      .unstack(fill_value=0)\n",
    "breed_probs = breed_counts.div(breed_counts.sum(axis=1), axis=0)\n",
    "global_probs = df_full['Outcome Type']\\\n",
    "                .value_counts(normalize=True).to_dict()\n",
    "\n",
    "for outcome in breed_probs.columns:\n",
    "    X[f'breed_prob_{outcome}'] = X['Breed'].map(breed_probs[outcome])\\\n",
    "                                        .fillna(global_probs[outcome])\n",
    "X.drop(columns=['Breed'], inplace=True)\n",
    "\n",
    "# … then your color bucketing, age, one‑hot on color category, etc. …\n",
    "\n",
    "# Fill missing values: For object columns, fill with \"Unknown\"; for numeric, fill with median.\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].fillna(\"Unknown\")\n",
    "    else:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "\n",
    "\n",
    "# # === 5. Encode Categorical Variables ===\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "print(\"categorical cols\", categorical_cols)\n",
    "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "# print(X[\"Intake Type\"].unique())\n",
    "# print(X[\"Intake Condition\"].unique())\n",
    "# print(X[\"Animal Type\"].unique())\n",
    "# print(X[\"Breed\"].unique())\n",
    "# print(X[\"Color Category\"].unique())\n",
    "# Ensure all features are numeric\n",
    "X = X.astype(float)\n",
    "\n",
    "print(\"Processed feature sample:\")\n",
    "\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0badea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Assign X_full and y_full for tuning\n",
    "X_full = X.copy()\n",
    "y_full = y_encoded.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e02fd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in c:\\users\\saifk\\appdata\\roaming\\python\\python39\\site-packages (4.3.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\saifk\\appdata\\roaming\\python\\python39\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (1.21.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\saifk\\appdata\\roaming\\python\\python39\\site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (1.4.32)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: Mako in c:\\users\\saifk\\appdata\\roaming\\python\\python39\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\saifk\\appdata\\roaming\\python\\python39\\site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc258d",
   "metadata": {},
   "source": [
    "Running the Optuna tuning on the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c8950b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:12:07,691] A new study created in memory with name: no-name-78bb93a0-098d-438a-b3a9-04af0cb07fbf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.860821\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.868326\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.867246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:17:59,270] Trial 0 finished with value: 0.384253869194326 and parameters: {'num_leaves': 73, 'max_depth': 10, 'learning_rate': 0.0023572195982527987, 'subsample': 0.9128722430506582, 'colsample_bytree': 0.562697722770656, 'min_child_samples': 96, 'reg_lambda': 8.49894773519296}. Best is trial 0 with value: 0.384253869194326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.880333\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.886883\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.885755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:22:33,720] Trial 1 finished with value: 0.37764626385954486 and parameters: {'num_leaves': 42, 'max_depth': 15, 'learning_rate': 0.0012459970191869751, 'subsample': 0.7789145720635944, 'colsample_bytree': 0.9161013397474682, 'min_child_samples': 45, 'reg_lambda': 0.018750468028232378}. Best is trial 0 with value: 0.384253869194326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[532]\tvalid_0's multi_logloss: 0.841194\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's multi_logloss: 0.849687\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[433]\tvalid_0's multi_logloss: 0.849164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:23:35,094] Trial 2 finished with value: 0.40433068308146414 and parameters: {'num_leaves': 82, 'max_depth': 4, 'learning_rate': 0.03781276602727258, 'subsample': 0.6265458956868566, 'colsample_bytree': 0.8896544944005711, 'min_child_samples': 21, 'reg_lambda': 0.3112995658918904}. Best is trial 2 with value: 0.40433068308146414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 0.839924\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's multi_logloss: 0.84974\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_logloss: 0.848261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:23:54,390] Trial 3 finished with value: 0.41197995057628817 and parameters: {'num_leaves': 75, 'max_depth': 8, 'learning_rate': 0.14526045233692922, 'subsample': 0.7275549031684927, 'colsample_bytree': 0.800324833803508, 'min_child_samples': 52, 'reg_lambda': 0.8514175545663637}. Best is trial 3 with value: 0.41197995057628817.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[452]\tvalid_0's multi_logloss: 0.839233\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[460]\tvalid_0's multi_logloss: 0.848957\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[461]\tvalid_0's multi_logloss: 0.847465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:25:52,282] Trial 4 finished with value: 0.41047899812516436 and parameters: {'num_leaves': 62, 'max_depth': 8, 'learning_rate': 0.014887356208053888, 'subsample': 0.9145099324425869, 'colsample_bytree': 0.7464286260559454, 'min_child_samples': 90, 'reg_lambda': 0.8152888863943535}. Best is trial 3 with value: 0.41197995057628817.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.845529\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.854225\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.852835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:33:23,077] Trial 5 finished with value: 0.4059664864426534 and parameters: {'num_leaves': 97, 'max_depth': 11, 'learning_rate': 0.002772310936430767, 'subsample': 0.9254561017651506, 'colsample_bytree': 0.7020494999712577, 'min_child_samples': 39, 'reg_lambda': 0.03320649613597291}. Best is trial 3 with value: 0.41197995057628817.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's multi_logloss: 0.840081\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.84957\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.848477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:33:53,243] Trial 6 finished with value: 0.4087687611813194 and parameters: {'num_leaves': 104, 'max_depth': 7, 'learning_rate': 0.06948876962108243, 'subsample': 0.9819748147394038, 'colsample_bytree': 0.7549787946679074, 'min_child_samples': 88, 'reg_lambda': 0.050096537187753025}. Best is trial 3 with value: 0.41197995057628817.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's multi_logloss: 0.840273\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_logloss: 0.850075\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's multi_logloss: 0.848893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:34:09,937] Trial 7 finished with value: 0.40987323544851356 and parameters: {'num_leaves': 111, 'max_depth': 5, 'learning_rate': 0.1900119587656553, 'subsample': 0.8415029095462363, 'colsample_bytree': 0.7796653248301413, 'min_child_samples': 44, 'reg_lambda': 1.754853349531811}. Best is trial 3 with value: 0.41197995057628817.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's multi_logloss: 0.842096\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's multi_logloss: 0.851004\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's multi_logloss: 0.850727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:35:28,119] Trial 8 finished with value: 0.4126591546668496 and parameters: {'num_leaves': 122, 'max_depth': 14, 'learning_rate': 0.02488190246631083, 'subsample': 0.6089319175272458, 'colsample_bytree': 0.8590622623545716, 'min_child_samples': 44, 'reg_lambda': 0.003622933097101497}. Best is trial 8 with value: 0.4126591546668496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's multi_logloss: 0.839214\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 0.849407\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's multi_logloss: 0.848042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:35:53,490] Trial 9 finished with value: 0.4119381399929949 and parameters: {'num_leaves': 36, 'max_depth': 11, 'learning_rate': 0.07865752348687625, 'subsample': 0.9290916242564145, 'colsample_bytree': 0.7206818110753674, 'min_child_samples': 89, 'reg_lambda': 0.004366567030366397}. Best is trial 8 with value: 0.4126591546668496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\tvalid_0's multi_logloss: 0.841165\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's multi_logloss: 0.849816\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's multi_logloss: 0.849671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:38:15,690] Trial 10 finished with value: 0.4142831661274733 and parameters: {'num_leaves': 122, 'max_depth': 16, 'learning_rate': 0.012295555988009719, 'subsample': 0.5016370896820155, 'colsample_bytree': 0.9564976280542989, 'min_child_samples': 12, 'reg_lambda': 0.0010792826300803577}. Best is trial 10 with value: 0.4142831661274733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[344]\tvalid_0's multi_logloss: 0.8413\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's multi_logloss: 0.85022\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's multi_logloss: 0.849598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:40:48,672] Trial 11 finished with value: 0.41412663012732026 and parameters: {'num_leaves': 127, 'max_depth': 16, 'learning_rate': 0.011454586652525828, 'subsample': 0.5072554689981483, 'colsample_bytree': 0.9867791919587336, 'min_child_samples': 10, 'reg_lambda': 0.0011713898274647993}. Best is trial 10 with value: 0.4142831661274733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[435]\tvalid_0's multi_logloss: 0.841406\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's multi_logloss: 0.850089\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[418]\tvalid_0's multi_logloss: 0.849405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:44:11,270] Trial 12 finished with value: 0.4129303440839353 and parameters: {'num_leaves': 127, 'max_depth': 16, 'learning_rate': 0.009049837387586308, 'subsample': 0.5081600208317252, 'colsample_bytree': 0.9952429059618526, 'min_child_samples': 6, 'reg_lambda': 0.0010837441088158038}. Best is trial 10 with value: 0.4142831661274733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[573]\tvalid_0's multi_logloss: 0.840107\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[580]\tvalid_0's multi_logloss: 0.848823\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[553]\tvalid_0's multi_logloss: 0.848528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:48:40,445] Trial 13 finished with value: 0.4134504777995816 and parameters: {'num_leaves': 97, 'max_depth': 13, 'learning_rate': 0.007244193069973117, 'subsample': 0.5064923839465701, 'colsample_bytree': 0.9987648142593202, 'min_child_samples': 11, 'reg_lambda': 0.0012951552897274947}. Best is trial 10 with value: 0.4142831661274733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.842275\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.851693\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.850651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 23:51:45,470] Trial 14 finished with value: 0.4049047930619114 and parameters: {'num_leaves': 15, 'max_depth': 13, 'learning_rate': 0.005892365443801871, 'subsample': 0.58582704808971, 'colsample_bytree': 0.9348504410951178, 'min_child_samples': 25, 'reg_lambda': 0.0069971879901187615}. Best is trial 10 with value: 0.4142831661274733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's multi_logloss: 0.841165\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's multi_logloss: 0.85111\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-04-16 23:53:40,268] Trial 15 failed with parameters: {'num_leaves': 117, 'max_depth': 16, 'learning_rate': 0.01774142981741026, 'subsample': 0.6975965711505208, 'colsample_bytree': 0.6290678448742418, 'min_child_samples': 28, 'reg_lambda': 0.011656179632202137} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\saifk\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\saifk\\AppData\\Local\\Temp\\ipykernel_35356\\705198822.py\", line 48, in objective\n",
      "    clf.fit(\n",
      "  File \"C:\\Users\\saifk\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\sklearn.py\", line 1560, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\saifk\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\saifk\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"C:\\Users\\saifk\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\basic.py\", line 4155, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-16 23:53:40,307] Trial 15 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 76>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m     66\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     67\u001b[0m     pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m     )\n\u001b[0;32m     72\u001b[0m )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# 6) Run for up to 60 minutes (3600 sec) or 100 trials, whichever comes first\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2400\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# inject params + n_estimators + silent mode\u001b[39;00m\n\u001b[0;32m     46\u001b[0m clf \u001b[38;5;241m=\u001b[39m LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_logloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m preds \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     56\u001b[0m cv_scores\u001b[38;5;241m.\u001b[39mappend(balanced_accuracy_score(y_val, preds))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\sklearn.py:1560\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1557\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1558\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1560\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    311\u001b[0m     cb(\n\u001b[0;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m         )\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4154\u001b[0m _safe_call(\n\u001b[1;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4159\u001b[0m )\n\u001b[0;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "\n",
    "\n",
    "# 1) Pre-materialize your features once\n",
    "# --------------------------------------------------\n",
    "# (Assuming X_full, y_full are your preprocessed DataFrame/Series)\n",
    "X_full_mat = X_full.values.astype(np.float32)\n",
    "y_full_arr = y_full\n",
    "\n",
    "# 2) Define Stratified 3‑fold splitter\n",
    "# --------------------------------------------------\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # sample hyperparameters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective':    'multiclass',\n",
    "        'num_class':    len(le_y.classes_),\n",
    "        'n_jobs':       -1,\n",
    "        'num_leaves':   trial.suggest_int('num_leaves', 15, 127),\n",
    "        'max_depth':    trial.suggest_int('max_depth', 3, 16),\n",
    "        'learning_rate':    trial.suggest_loguniform('learning_rate', 1e-3, 0.3),\n",
    "        'subsample':        trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_samples':trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'reg_lambda':       trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
    "        'verbose': -1      # silence internal logs\n",
    "    }\n",
    "\n",
    "    cv_scores = []\n",
    "    for train_idx, valid_idx in skf.split(X_full_mat, y_full_arr):\n",
    "        X_tr, X_val = X_full_mat[train_idx], X_full_mat[valid_idx]\n",
    "        y_tr, y_val = y_full_arr[train_idx], y_full_arr[valid_idx]\n",
    "\n",
    "        # inject params + n_estimators + silent mode\n",
    "        clf = LGBMClassifier(**params, n_estimators=1000)\n",
    "\n",
    "        clf.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='multi_logloss',\n",
    "            callbacks=[early_stopping(stopping_rounds=50)]\n",
    "        )\n",
    "\n",
    "        preds = clf.predict(X_val)\n",
    "        cv_scores.append(balanced_accuracy_score(y_val, preds))\n",
    "\n",
    "    return sum(cv_scores) / len(cv_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5) Build the study with a MedianPruner\n",
    "# --------------------------------------------------\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=10,  # let 10 trials run to build median\n",
    "        n_warmup_steps=0,\n",
    "        interval_steps=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# 6) Run for up to 60 minutes (3600 sec) or 100 trials, whichever comes first\n",
    "# --------------------------------------------------\n",
    "study.optimize(objective, n_trials=100, timeout=2400)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "print(\"Best CV balanced accuracy:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec38fdf",
   "metadata": {},
   "source": [
    "Late attempt to train the model on the full data set after optuna used just a smaller subset, but ran out of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a699fbed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier()\n\u001b[1;32m----> 2\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train_full\u001b[49m, y_train_full)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_full' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = lgb.LGBMClassifier()\n",
    "best_model.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b119d",
   "metadata": {},
   "source": [
    "Adjusting the test data so that the model could work on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0097cf6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply the model to the test data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# === Load and preprocess test.csv ===\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m test_ids \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Drop columns not used in prediction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.csv'"
     ]
    }
   ],
   "source": [
    "# Apply the model to the test data\n",
    "# === Load and preprocess test.csv ===\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_ids = test_df['Id']\n",
    "\n",
    "# Drop columns not used in prediction\n",
    "drop_cols_test = ['Found Location', 'Date of Birth', 'Id']\n",
    "X_test = test_df.drop(columns=drop_cols_test, errors='ignore')\n",
    "\n",
    "# Feature engineering (same as training)\n",
    "X_test['Color Category'] = X_test['Color'].apply(simplify_color)\n",
    "X_test.drop(columns=['Color'], inplace=True)\n",
    "\n",
    "X_test['Age in Days'] = X_test['Age upon Intake'].apply(age_to_days)\n",
    "X_test.drop(columns=['Age upon Intake'], inplace=True)\n",
    "\n",
    "X_test['Intake Time'] = pd.to_datetime(test_df['Intake Time'], errors='coerce')\n",
    "X_test['Intake Hour'] = X_test['Intake Time'].dt.hour\n",
    "X_test['Weekday'] = X_test['Intake Time'].dt.weekday\n",
    "X_test['Season'] = X_test['Intake Time'].dt.month.map({\n",
    "    12: 'winter', 1: 'winter', 2: 'winter',\n",
    "    3: 'spring', 4: 'spring', 5: 'spring',\n",
    "    6: 'summer', 7: 'summer', 8: 'summer',\n",
    "    9: 'fall', 10: 'fall', 11: 'fall'\n",
    "})\n",
    "X_test.drop(columns=['Intake Time'], inplace=True, errors='ignore')\n",
    "\n",
    "# Fill missing values\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].dtype == 'object':\n",
    "        X_test[col] = X_test[col].fillna(\"Unknown\")\n",
    "    else:\n",
    "        X_test[col] = X_test[col].fillna(X_test[col].median())\n",
    "\n",
    "# Ensure categorical types match training\n",
    "for col in categorical_cols:\n",
    "    if col in X_test.columns:\n",
    "        X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1caed",
   "metadata": {},
   "source": [
    "Run the test data through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Make predictions ===\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_labels = le_y.inverse_transform(y_test_pred)\n",
    "\n",
    "# === Create submission ===\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'Outcome Type': y_test_labels\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"submission4149.csv\", index=False)\n",
    "print(\"submission.csv created with test predictions!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
